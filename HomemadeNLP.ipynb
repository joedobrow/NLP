{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import brown\n",
    "import os\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "#nltk.download('brown')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "import gensim\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\tThe/at Fulton/np-tl County/nn-tl Grand/jj-tl Jury/nn-tl said/vbd Friday/nr an/at investigation/nn of/in Atlanta's/np$ recent/jj primary/nn election/nn produced/vbd ``/`` no/at evidence/nn ''/'' that/cs any/dti irregularities/nns took/vbd place/nn ./.\\n\\n\\n\\tThe/at jury/nn further/rbr said/vbd in/in term-end/nn presentments/nns that/cs the/at City/nn-tl Executive/jj-tl Committee/nn-tl ,/, which/wdt had/hvd over-all/jj charge/nn of/in the/at election/nn ,/, ``/`` deserves/vbz the/at praise/nn and/cc thanks/nns of/in the/at City/nn-tl of/in-tl Atlanta/np-tl ''/'' for/in the/at manner/nn in/in which/wdt the/at election/nn was/bedz conducted/vbn ./.\\n\\n\\n\\tThe/at September-October/np term/nn jury/nn had/hvd been/ben charged/vbn by/in Fulton/np-tl Superior/jj-tl Court/nn-tl Judge/nn-tl Durwood/np Pye/np to/to investigate/vb reports/nns of/in possible/jj ``/`` irregularities/nns ''/'' in/in the/at hard-fought/jj primary/nn which/wdt was/bedz won/vbn by/in Mayor-nominate/nn-tl Ivan/np Allen/np Jr./\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Million word corpus of text from 500 different sources. \n",
    "brown.raw()[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    \n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub('\\/\\S+ ', ' ', text)\n",
    "    text = re.sub(' \\.\\/\\.', '.', text)\n",
    "    text = re.sub('`` ', '\\\"', text)\n",
    "    text = re.sub(' \\\\\\'\\\\\\'', '\\\"', text)\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text\n",
    "\n",
    "def bow_features(data, common_words):\n",
    "    \n",
    "    bow = []\n",
    "    bow.append(list(data.iloc[:, 1]))\n",
    "    bow.append(list(data.iloc[:, 0]))\n",
    "    \n",
    "    for i in range(len(common_words)):\n",
    "        bow.append(list(np.zeros(len(bow[0]))))\n",
    "    \n",
    "    for i, text in enumerate(bow[0]):\n",
    "        \n",
    "        for word in text.split():\n",
    "            for word2 in range(len(common_words)):\n",
    "                if word == common_words[word2]:\n",
    "                    bow[word2 + 2][i] += 1\n",
    "    \n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Fulton County Grand Jury said Friday an investigation of Atlanta's recent primary election produced \"no evidence\" that any irregularities took place. The jury further said in term-end presentments that the City Executive Committee , which had over-all charge of the election , \"deserves the praise and thanks of the City of Atlanta\" for the manner in which the election was conducted. The September-October term jury had been charged by Fulton Superior Court Judge Durwood Pye to investigate reports of possible \"irregularities\" in the hard-fought primary which was won by Mayor-nominate Ivan Allen Jr.. \"Only a relative handful of such reports was received\" , the jury said , \"considering the widespread interest in the election , the number of voters and the size of this city\". The jury said it did find that many of Georgia's registration and election laws \"are outmoded or inadequate and often ambiguous\". It recommended that Fulton legislators act \"to have these laws studied and revised to\n",
      "\n",
      "Length of Brown: 6052357\n"
     ]
    }
   ],
   "source": [
    "brown_clean = text_cleaner(brown.raw())\n",
    "print(brown_clean[:1000])\n",
    "print('\\nLength of Brown:', len(brown_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "nlp.max_length=6500000\n",
    "brown_doc = nlp(brown_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['regard', 'atlanta', \"'s\", 'new', 'multi', 'million', 'dollar', 'airport', 'the', 'jury', 'recommend', 'that', 'when', 'the', 'new', 'management', 'take', 'charge', 'january', '1', 'the', 'airport', 'be', 'operate', 'in', 'a', 'manner', 'that', 'will', 'eliminate', 'political', 'influence']\n",
      "We have 57952 sentences and 6052357 tokens.\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for sentence in brown_doc.sents:\n",
    "    sentence = [\n",
    "        token.lemma_.lower()\n",
    "        for token in sentence\n",
    "        if not token.is_punct\n",
    "        # Keeping stops in\n",
    "    ]\n",
    "    sentences.append(sentence)\n",
    "\n",
    "\n",
    "print(sentences[20])\n",
    "print('We have {} sentences and {} tokens.'.format(len(sentences), len(brown_clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "vector_size = 100\n",
    "\n",
    "model = word2vec.Word2Vec(\n",
    "    sentences,\n",
    "    workers=3,     \n",
    "    min_count=10,  \n",
    "    window=8,      \n",
    "    sg=0,          # Use CBOW because our corpus is small.\n",
    "    sample=.001 ,  # Penalize frequent words.\n",
    "    size=vector_size,      # Word vector length.\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('/Data Science/word2vec-nlp-tutorial/labeledTrainData.tsv', sep='\\t')\n",
    "reviews.drop('id', 1, inplace=True)\n",
    "\n",
    "sentence_vector_list = []\n",
    "for sentence in reviews.review:\n",
    "    split = sentence.split()\n",
    "    total_vec = np.zeros(vector_size)\n",
    "    word_count = 0\n",
    "    for word in split:\n",
    "        try:\n",
    "            total_vec += model.wv.get_vector(word.lower())\n",
    "            word_count += 1\n",
    "        except:\n",
    "            None\n",
    "    total_vec /= word_count\n",
    "    sentence_vector_list.append(total_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.DataFrame()\n",
    "review_df['Sentiment'] = reviews.sentiment\n",
    "for i in range(vector_size):\n",
    "    vector_element_list = []\n",
    "    for review in range(len(review_df)):\n",
    "        vector_element_list.append(sentence_vector_list[review][i])\n",
    "    review_df['Element {}'.format(i)] = vector_element_list\n",
    "    \n",
    "review_df['RawReview'] = reviews.review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6304"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = review_df.iloc[:, 1:-1]\n",
    "Y = review_df.Sentiment\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= 0.2)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_common_words = 100\n",
    "common_text = []\n",
    "for text in reviews.review:\n",
    "    for word in text.split():\n",
    "        common_text.append(word)\n",
    "common_words = [item[0] for item in Counter(common_text).most_common(num_common_words)]\n",
    "\n",
    "word_counts = bow_features(reviews, common_words)\n",
    "\n",
    "bow_reviews = pd.DataFrame()\n",
    "bow_reviews['Sentiment'] = review_df.Sentiment\n",
    "for feature in range(num_common_words):\n",
    "    bow_reviews[common_words[feature]] = word_counts[feature + 2]\n",
    "bow_reviews['Text'] = review_df.RawReview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6504"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = bow_reviews.iloc[:, 1:-1]\n",
    "Y = bow_reviews.Sentiment\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= 0.2)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Larger vector size and more common words and skip gram instead of cbow\n",
    "\n",
    "vector_size = 200\n",
    "\n",
    "model = word2vec.Word2Vec(\n",
    "    sentences,\n",
    "    workers=3,     \n",
    "    min_count=10,  \n",
    "    window=8,      \n",
    "    sg=1,          # Use CBOW because our corpus is small.\n",
    "    sample=.001 ,  # Penalize frequent words.\n",
    "    size=vector_size,      # Word vector length.\n",
    "    hs=1           # Use hierarchical softmax.\n",
    ")\n",
    "\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_common_words = 500\n",
    "common_text = []\n",
    "for text in reviews.review:\n",
    "    for word in text.split():\n",
    "        common_text.append(word)\n",
    "common_words = [item[0] for item in Counter(common_text).most_common(num_common_words)]\n",
    "\n",
    "word_counts = bow_features(reviews, common_words)\n",
    "\n",
    "bow_reviews = pd.DataFrame()\n",
    "bow_reviews['Sentiment'] = review_df.Sentiment\n",
    "for feature in range(num_common_words):\n",
    "    bow_reviews[common_words[feature]] = word_counts[feature + 2]\n",
    "bow_reviews['Text'] = review_df.RawReview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7062"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = bow_reviews.iloc[:, 1:-1]\n",
    "Y = bow_reviews.Sentiment\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= 0.2)\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Able to improve BOW model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
